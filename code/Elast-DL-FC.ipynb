{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"path\": \"../data/\",\n",
      "        \"files\": {\n",
      "            \"baskets\": \"baskets.parquet\",\n",
      "            \"coupons\": \"coupons.parquet\",\n",
      "            \"coupons_index\": \"coupon_index.parquet\"\n",
      "        }\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"test_week\": 90,\n",
      "        \"n_shoppers\": 2000,\n",
      "        \"n_products\": 250,\n",
      "        \"train_window\": 4,\n",
      "        \"trend_windows\": [\n",
      "            1,\n",
      "            3,\n",
      "            5\n",
      "        ],\n",
      "        \"n_coupons\": 5,\n",
      "        \"discounts\": [\n",
      "            0.15,\n",
      "            0.2,\n",
      "            0.25,\n",
      "            0.3\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "Read dataset.parquet.gzip from cache...\n",
      "Successfully read dataset.parquet.gzip into memory.\n"
     ]
    }
   ],
   "source": [
    "import Utils\n",
    "from DataLoader import DataLoader\n",
    "from FeatureCreator import FeatureCreator\n",
    "from Model import Model\n",
    "from CouponCreator import CouponCreator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "config = Utils.read_json('../config.json')\n",
    "Utils.print_json(config)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(config)\n",
    "dataset = dataloader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86, 87, 88, 89, 90], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'product'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-0b43e3fc6387>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elasticities'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'product'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elasticities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   8190\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8192\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   8193\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8194\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1681\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1683\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'product'"
     ]
    }
   ],
   "source": [
    " \n",
    "temp = pd.DataFrame()\n",
    "#temp['product'] = np.arange(250)\n",
    "elast = []\n",
    "\n",
    "train_dataset = dataset[dataset['week'] < test_week]\n",
    "for i in range(250):\n",
    "    product             = train_dataset[train_dataset['product'] == i]\n",
    "    \n",
    "    reg_price_all       = product[product['discount'] == 0]\n",
    "    discount_30_all     = product[product['discount'] == 0.3]\n",
    "    \n",
    "    \n",
    "    reg_price_offer      = len(reg_price_all)\n",
    "    discount_30_offer    = len(discount_30_all)\n",
    "    \n",
    "    reg_price_buy        = len(reg_price_all[reg_price_all['purchased'] == 1])\n",
    "    discount_30_buy      = len(discount_30_all[discount_30_all['purchased'] == 1])\n",
    "\n",
    "    \n",
    "    reg_price_buy_rate   = reg_price_buy / reg_price_offer\n",
    "    discount_buy_rate    = discount_30_buy / discount_30_offer\n",
    "    \n",
    "    elast.append((discount_buy_rate - reg_price_buy_rate) / (0.3 * reg_price_buy_rate))\n",
    "      \n",
    "    \n",
    "temp['elasticities'] = elast\n",
    "dataset = dataset.merge(temp, how='left', on='product')\n",
    "\n",
    "temp['elasticities'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4.012936\n",
       "1      -0.309028\n",
       "2       4.584342\n",
       "3      -3.333333\n",
       "4       9.203956\n",
       "         ...    \n",
       "245    -3.333333\n",
       "246     4.138095\n",
       "247    20.770891\n",
       "248     0.791287\n",
       "249     1.761613\n",
       "Name: elasticities, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['elasticities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_discount = dataset[dataset['discount'] == 0]\n",
    "no_discount_buy = dataset[dataset['price']  > 0]\n",
    "\n",
    "discount_30 = dataset[dataset['discount'] == 0.3]\n",
    "discount_30_buy = dataset[dataset['price'] > 0]\n",
    "\n",
    "\n",
    "no_discount_all = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount_all')\n",
    "no_discount_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount_buy')\n",
    "discount_30_all = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30_all')\n",
    "discount_30_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30_buy')\n",
    "\n",
    "dataset = dataset.merge(no_discount_all, how='left', on=(['week']))\n",
    "dataset = dataset.merge(no_discount_buy, how='left', on=(['week']))\n",
    "dataset = dataset.merge(discount_30_all, how='left', on=(['week']))\n",
    "dataset = dataset.merge(discount_30_buy, how='left', on=(['week']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>no_discount_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week                                    no_discount_all\n",
       "0    86  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "1    87  [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
       "2    88  [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
       "3    89  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "4    90  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_discount_all\n",
    "#no_discount_all = dataset['no_discount_all'][product].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATALOADER\n",
    "    \n",
    "    '''\n",
    "    Helper to derive price elasticities\n",
    "    create list for \n",
    "    '''\n",
    "    \n",
    "no_discount = dataset[dataset['discount'] == 0]\n",
    "no_discount_buy = dataset[dataset['price']  > 0]\n",
    "\n",
    "discount_30 = dataset[dataset['discount'] == 0.3]\n",
    "discount_30_buy = dataset[dataset['price'] > 0]\n",
    "\n",
    "\n",
    "no_discount_all = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount_all')\n",
    "no_discount_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount_buy')\n",
    "discount_30_all = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30_all')\n",
    "discount_30_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30_buy')\n",
    "\n",
    "dataset = dataset.merge(no_discount_all, how='left', on=(['week']))\n",
    "dataset = dataset.merge(no_discount_buy, how='left', on=(['week']))\n",
    "dataset = dataset.merge(discount_30_all, how='left', on=(['week']))\n",
    "dataset = dataset.merge(discount_30_buy, how='left', on=(['week']))\n",
    "\n",
    "\n",
    "\n",
    "FEATURECREATOR\n",
    "\n",
    "for product in dataset['product'].unique()\n",
    "    no_discount_all = dataset['no_discount_all'][product].count()\n",
    "    no_discount_buy = dataset['no_discount_buy'][product].count()\n",
    "    discount_30_all = dataset['discount_30_all'][product].count()\n",
    "    discount_30_buy = dataset['discount_30_buy'][product].count()\n",
    "    \n",
    "    reg_price_buy_rate = no_discount_buy / no_discount_all\n",
    "    reg_price_offer = total_basket_count - all_discounts_offers\n",
    "\n",
    "    \n",
    "    product_elast = (discount_buy_rate - reg_price_buy_rate) / (0.3 * reg_price_buy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATALOADER\n",
    "\n",
    "def elasticities_prep(dataset):\n",
    "    '''\n",
    "    Helper to derive price elasticities\n",
    "    create list for \n",
    "    '''\n",
    "    no_discount = baskets[baskets['discount'] == 0]\n",
    "    no_discount_buy = baskets[baskets['price']  > 0]\n",
    "\n",
    "    discount_30 = baskets[baskets['discount'] == 30]\n",
    "    discount_30_buy = baskets[baskets['price'] > 0]\n",
    "\n",
    "\n",
    "    no_discount = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount')\n",
    "    no_discount_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='no_discount_buy')\n",
    "    discount_30 = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30')\n",
    "    discount_30_buy = no_discount.groupby(['week'])['product'].apply(list).reset_index(name='discount_30_buy')\n",
    "\n",
    "    reg_price_offer = 100000 - discount_30\n",
    "\n",
    "\n",
    "FEATURECREATOR\n",
    "\n",
    "for product in baskets['products'].unique()\n",
    "    discount_buy_rate = discount_30_buy / discount_30\n",
    "    reg_price_buy_rate = no_discount_buy / no_discount\n",
    "    elast = []\n",
    "    temp = pd.DataFrame()\n",
    "    temp['product'] = np.arange(250)\n",
    "    temp['week'] = i + 1\n",
    "    elast.append((discount_buy_rate - reg_price_buy_rate) / (0.3 * reg_price_buy_rate))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                reg_price_buy = len(reg_price[reg_price['discount'] == 0])\n",
    "                all_discounts_offers = len(reg_price[reg_price['discount'] > 0])\n",
    "                reg_price_offer = total_basket_count - all_discounts_offers\n",
    "                reg_price_buy_rate = reg_price_buy / reg_price_offer\n",
    "                discount_30 = reg_price[reg_price['discount'] == 30]\n",
    "                discount_30_offer = len(discount_30)\n",
    "                discount_30_buy = (discount_30['price'] != 0).sum()\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
